import chromadb
from sentence_transformers import SentenceTransformer
import requests
import random
import json
from datetime import datetime

CHROMA_PATH = r"C:/Users/Fyn/Desktop/rag/chroma_db"

embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)

collection = chroma_client.get_collection("toeic_questions")
scenario_collection = chroma_client.get_collection("toeic_scenarios")

# â¤ éš¨æ©Ÿé¸æ“‡ä¸€å€‹æƒ…å¢ƒé—œéµè©
scenario_keywords = [
    "ä¼æ¥­ç™¼å±•", "å¤–é£Ÿ", "å¨›æ¨‚", "é‡‘èï¼é ç®—", "ä¸€èˆ¬å•†å‹™", "ä¿å¥", "æˆ¿å±‹ï¼å…¬å¸åœ°ç”¢",
    "è£½é€ æ¥­", "è¾¦å…¬å®¤", "äººäº‹", "æ¡è³¼", "æŠ€è¡“å±¤é¢", "æ—…éŠ"
]
scenario_text = random.choice(scenario_keywords)

query_text = "Part 5 grammar TOEIC question"
query_embedding = embedding_model.encode(query_text).tolist()
results = collection.query(query_embeddings=[query_embedding], n_results=3)

scenario_embedding = embedding_model.encode(scenario_text).tolist()
scenario_results = scenario_collection.query(query_embeddings=[scenario_embedding], n_results=1)

similar_questions = results["documents"][0]
scenario_context = scenario_results["documents"][0][0] if scenario_results["documents"] else scenario_text

context = "\n\n".join(similar_questions)

prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­ TOEIC å‡ºé¡Œå°ˆå®¶ã€‚è«‹æ ¹æ“šä¸‹åˆ—æ¸¬é©—æƒ…å¢ƒèˆ‡ç¯„ä¾‹é¡Œç›®ï¼Œ**ç”Ÿæˆä¸€é¡Œæ–°çš„ TOEIC Part 5 æ–‡æ³•å–®å¥å¡«ç©ºé¡Œ**ï¼Œä¸¦**ä»¥ JSON é™£åˆ—æ ¼å¼**å›å‚³çµæœã€‚æ¯é¡ŒåŒ…å«ï¼š

è«‹ä»¥ json æ ¼å¼è¼¸å‡ºå¦‚ä¸‹ï¼ˆåš´æ ¼ä¾ç…§ï¼‰ï¼š
[
  {{
    "question": "é¡Œç›®å…§å®¹ï¼ˆå–®å¥å¡«ç©ºï¼‰",
    "option": {{
      "A": "é¸é … A",
      "B": "é¸é … B",
      "C": "é¸é … C",
      "D": "é¸é … D"
    }},
    "answer": "A",
    "explanation": "è§£æ(è«‹ä¸€å®šè¦å¯«å‡ºä¾†ï¼Œä¸¦ä¸”è¦æœ‰é‚è¼¯æ€§)"
  }}
]
### æ¸¬é©—æƒ…å¢ƒï¼š
{scenario_context}

### ç¯„ä¾‹é¡Œç›®ï¼ˆä¾›é¢¨æ ¼åƒè€ƒï¼‰ï¼š
{context}

è«‹ç›´æ¥è¼¸å‡ºç´” JSON é™£åˆ—ï¼Œ**ä¸è¦åŠ å…¥ä»»ä½•æ–‡å­—èªªæ˜ã€æ¨™é¡Œæˆ–è¨»è§£**ï¼Œä¹Ÿ**ä¸è¦ä½¿ç”¨ markdown æ ¼å¼æ¨™ç±¤ï¼ˆ```ï¼‰**ã€‚

"""

response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "llama3",
        "prompt": prompt,
        "stream": False
    }
)

# å–å¾—å›æ‡‰æ–‡å­—ä¸¦è§£æ
raw_output = response.json()["response"]

try:
    questions = json.loads(raw_output)

    # â¤ å¼·åˆ¶è½‰æˆ list çµ±ä¸€æ ¼å¼
    if isinstance(questions, dict):
        questions = [questions]
    elif not isinstance(questions, list):
        raise ValueError("âŒ LLM å›å‚³æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è½‰ç‚º listã€‚")

    # â¤ å°è£æˆä¸€ç­† JSON è³‡æ–™ï¼ŒåŠ ä¸Šæ™‚é–“èˆ‡æƒ…å¢ƒ
    output_json = {
        "datetime": datetime.now().isoformat(),
        "scenario": scenario_text,
        "questions": questions
    }


    # â¤ æŒ‡å®šè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    output_path = "C:/Users/Fyn/Desktop/rag/json/toeic_part5.jsonl"

    # â¤ å¯«å…¥ JSONLï¼ˆé€è¡Œå„²å­˜ï¼‰
    with open(output_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(output_json, ensure_ascii=False) + "\n")

    # é¡¯ç¤ºçµæœ
    print(f"âœ… å·²å°‡é¡Œç›®è¿½åŠ å„²å­˜è‡³ {output_path}")
    print(f"ğŸ¯ æœ¬æ¬¡éš¨æ©Ÿæƒ…å¢ƒï¼šã€Œ{scenario_text}ã€\n")
    print("âœ… ç”Ÿæˆçš„æ–°é¡Œç›®ï¼ˆç¬¬ä¸€é¡Œç¯„ä¾‹ï¼‰ï¼š\n")
    print(json.dumps(questions[0], ensure_ascii=False, indent=2))

except json.JSONDecodeError as e:
    print("âŒ JSON æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æ LLM è¼¸å‡ºï¼š", e)
    print("ğŸ” åŸå§‹ LLM å›æ‡‰å…§å®¹ï¼š\n", raw_output)
