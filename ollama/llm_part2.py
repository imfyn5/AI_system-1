import chromadb
from sentence_transformers import SentenceTransformer
import requests
import random
import json
from datetime import datetime
import demjson3 as demjson
import re
import os

# è³‡æ–™å„²å­˜è¨­å®š
CHROMA_PATH = r"C:/Users/Fyn/Desktop/rag/chroma_db"
JSONL_PATH = "C:/Users/Fyn/Desktop/rag/json/toeic_part2_db_ready.jsonl"

# åˆå§‹åŒ–
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)

collection = chroma_client.get_collection("toeic_part2")
scenario_collection = chroma_client.get_collection("toeic_scenarios")

# éš¨æ©Ÿé¸ä¸€å€‹æƒ…å¢ƒé—œéµè©
scenario_keywords = [
    "ä¼æ¥­ç™¼å±•", "å¤–é£Ÿ", "å¨›æ¨‚", "é‡‘èï¼é ç®—", "ä¸€èˆ¬å•†å‹™", "ä¿å¥", "æˆ¿å±‹ï¼å…¬å¸åœ°ç”¢",
    "è£½é€ æ¥­", "è¾¦å…¬å®¤", "äººäº‹", "æ¡è³¼", "æŠ€è¡“å±¤é¢", "æ—…éŠ"
]
scenario_text = random.choice(scenario_keywords)

# æŸ¥è©¢èªæ„ç›¸é—œçš„ç¯„ä¾‹é¡Œçµ„èˆ‡æƒ…å¢ƒæ–‡å­—
query_embedding = embedding_model.encode("Part 2 TOEIC listening conversation with 3 option").tolist()
results = collection.query(query_embeddings=[query_embedding], n_results=2)

scenario_embedding = embedding_model.encode(scenario_text).tolist()
scenario_results = scenario_collection.query(query_embeddings=[scenario_embedding], n_results=1)

similar_questions = results["documents"][0] if results["documents"] else []
scenario_context = scenario_results["documents"][0][0] if scenario_results["documents"] else scenario_text

context = "\n\n".join(similar_questions)

# ğŸ”§ ç”¢ç”Ÿ promptï¼ˆç¬¦åˆè³‡æ–™è¡¨æ ¼å¼ï¼‰
prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­ TOEIC å‡ºé¡Œå°ˆå®¶ã€‚è«‹æ ¹æ“šä¸‹åˆ—æ¸¬é©—æƒ…å¢ƒèˆ‡ç¯„ä¾‹é¡Œç›®ï¼Œç”Ÿæˆä¸€é¡Œæ–°çš„ TOEIC Part 2 è½åŠ›é¡Œçµ„ï¼ŒåŒ…å«ï¼š

1. ä¸€ç­† listening_materialï¼ˆä¸å« IDï¼‰
2. ä¸€ç­† questionï¼ˆä¸å« ID èˆ‡ material_idï¼‰
å…§å®¹å¿…é ˆå…¨ç‚ºè‹±æ–‡ã€‚
ç‚ºé¡Œç›®ä¸€å¥å•å¥ï¼Œé¸é …ä¸‰å¥ï¼Œé¸é …å¿…é ˆå‡ºç¾åœ¨transcpritçš„é¡Œç›®å¾Œé¢ï¼Œé¡Œç›®ä»¥å°è©±æˆ–å•ç­”ç‚ºä¸»ã€‚
è¼¸å‡º JSON æ ¼å¼å¦‚ä¸‹ï¼ˆä¸è¦æœ‰èªªæ˜ã€æ¨™é¡Œã€Markdownï¼‰:
{{
  "listening_material": {{
    "audio_url": "éŸ³æª” å…ˆç•™ç©º",
    "transcript": "é–‹é ­ä¸€å®šè¦æœ‰ Question.å¾Œæ¥é¡Œç›®å…§å®¹(ä¸€å¥å•å¥)ï¼Œç„¶å¾Œæ¥é¸é …å…§å®¹(ä¸‰å¥å°æ‡‰ä¸‰å€‹é¸é …A,B,C)",
    "accent": "å£éŸ³ å…ˆç•™ç©º",
    "topic": "{scenario_text}",
    "speaker_count": "1",
    "listening_level": "é›£åº¦(beginner,intermediate,advanced)",
    "created_at": "{datetime.now().isoformat()}",
    "updated_at": "{datetime.now().isoformat()}",
    "is_approved": "0",
    "rejection_reason": "å…ˆç•™ç©º"
  }},
  "questions": [
    {{
      "question_text": "transcript çš„é¡Œç›®ä¸€å¥",
      "question_type": "listen",
      "question_category": "é¡Œç›®ç¨®é¡(tense,pos,syntax,vocab)tenseæ™‚æ…‹, posè©æ€§, syntaxèªæ³•, vocabè©å½™",
      "passage_id": null,
      "question_image_url": null,
      "part"= "2",
      "option_a_text": "transcrpité¡Œç›®å¾Œçš„é¸é … A",
      "option_b_text": "transcrpité¡Œç›®å¾Œçš„é¸é … B",
      "option_c_text": "transcrpité¡Œç›®å¾Œçš„é¸é … C",
      "option_d_text": null,
      "is_correct": "æ­£ç¢ºå›ç­”(A, B, C)",
      "difficulty_level": "é›£åº¦(1,2,3,4,5)æ•¸å­—è¶Šå¤§è¶Šé›£",
      "explanation": "é¡Œç›®è§£æ",
      "created_at": "{datetime.now().isoformat()}",
      "updated_at": "{datetime.now().isoformat()}"
    }}
  ]
}}

### æ¸¬é©—æƒ…å¢ƒï¼š
{scenario_context}

### ç¯„ä¾‹é¡Œç›®ï¼ˆä¾›é¢¨æ ¼åƒè€ƒï¼‰ï¼š
{context}

è«‹ç¢ºä¿è¼¸å‡ºç‚ºåˆæ³•çš„ JSON é™£åˆ—æ ¼å¼ï¼š
- æ‰€æœ‰å­—ä¸²å¿…é ˆç”¨é›™å¼•è™ŸåŒ…ä½
- ä¸å¯çœç•¥é€—è™Ÿ
- `\n` å¿…é ˆè½‰ç‚ºå­—ä¸²è¡¨ç¤ºï¼ˆ\\nï¼‰ï¼Œä¸å¯å‡ºç¾çœŸæ­£çš„æ›è¡Œ
è«‹ç›´æ¥è¼¸å‡ºç´” JSON é™£åˆ—ï¼Œ**ä¸è¦æœ‰ä»»ä½•èªªæ˜æ–‡å­—ã€æ¨™é¡Œã€è¨»è§£æˆ– Markdown æ ¼å¼ã€‚**
"""

# ğŸ”„ ç™¼é€è«‹æ±‚è‡³æœ¬åœ° LLM
response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "llama3",
        "prompt": prompt,
        "stream": False
    }
)

raw_output = response.json()["response"]

# è™•ç†éæ³•å­—å…ƒ
def clean_text(text):
    return re.sub(r'[\x00-\x09\x0b\x0c\x0e-\x1f\x7f]', '', text)

cleaned_output = clean_text(raw_output)

try:
    data = json.loads(cleaned_output)
except json.JSONDecodeError:
    print("âš ï¸ JSON è§£æéŒ¯èª¤ï¼Œä½¿ç”¨ demjson å˜—è©¦è§£æ...")
    data = demjson.decode(cleaned_output)

# ğŸš€ è‡ªå‹•ç”¢ç”Ÿä¸»éµ
import uuid

# ğŸ”‘ ä½¿ç”¨ UUID ç”¢ç”Ÿ material_id èˆ‡ question_id
def generate_uuid():
    return str(uuid.uuid4())

material_id = generate_uuid()
data["listening_material"]["material_id"] = material_id

for q in data["questions"]:
    q["question_id"] = generate_uuid()
    q["material_id"] = material_id

# âœ… å„²å­˜ç‚º JSONL
with open(JSONL_PATH, "a", encoding="utf-8") as f:
    f.write(json.dumps(data, ensure_ascii=False) + "\n")

print(f"âœ… é¡Œç›®å·²å„²å­˜è‡³ {JSONL_PATH}")
print(f"ğŸ¯ æœ¬æ¬¡ä¸»é¡Œï¼šã€Œ{scenario_text}ã€")
print(f"ğŸ“ å°è©±ç¨¿ï¼š\n{data['listening_material']['transcript'].replace('\\n', '\\n')}")
for q in data["questions"]:
    print("å•é¡Œï¼š", q["question_text"])
    print("A:", q["option_a_text"])
    print("B:", q["option_b_text"])
    print("C:", q["option_c_text"])
    print("D:", q["option_d_text"])
    print("ans:", q["is_correct"])
    print("explanation:", q["explanation"])
    print()
